{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un exemple simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descente de gradient ordinaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'un jeu d'entrainement\n",
    "import numpy as np\n",
    "x=np.array([[0, 0,1], \n",
    "            [2, 2,4], \n",
    "            [1, 4,1],\n",
    "            [10, 3,0],\n",
    "            [1,1,1]])\n",
    "y=np.array([15.5,\n",
    "            30,\n",
    "            25.5,\n",
    "           27,\n",
    "           17.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression() # création d'un objet LinearRegression\n",
    "reg.fit(x, y) # apprentissage avec la méthode fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.13296672306825"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# affichage de l'intercept theta_0\n",
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76128032, 2.40073322, 2.88141568])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# affichage de des coefficients theta_j avec j>1\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.0143824 , 29.98265651, 25.3785956 , 26.94796954, 18.17639594])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions du modèles sur données d'entrainement\n",
    "y_hat=reg.predict(x)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14221658206429777"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcul de la MSE sur le jeu d'entrainement\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'un jeu de test\n",
    "import numpy as np\n",
    "x_test=np.array([[3, 5,7], \n",
    "                 [7, 0,8]])\n",
    "y_test=np.array([48,\n",
    "                39])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([46.59038353, 40.51325437])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions du modèles sur données de test\n",
    "y_hat_test=reg.predict(x_test)\n",
    "y_hat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1384786910666325"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcul de la MSE sur le jeu de test\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, y_hat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descente de gradient stochastique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(eta0=0.001, learning_rate='constant', max_iter=100000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "reg = SGDRegressor(fit_intercept=True,learning_rate=\"constant\",eta0=0.001,max_iter=100000)\n",
    "reg.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.89650841])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.86041433, 2.80755161, 3.39858884])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.29509725, 30.82679563, 25.38571799, 26.9233065 , 16.96306318])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat=reg.predict(x)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1704861173061283"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcul de la MSE sur le jeu d'entrainement\n",
    "mean_squared_error(y, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([50.30563129, 43.10811941])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions du modèles sur données de test\n",
    "y_hat_test=reg.predict(x_test)\n",
    "y_hat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.096290379313016"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcul de la MSE sur le jeu de test\n",
    "mean_squared_error(y_test, y_hat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un exemple plus complet à partir de données importées\n",
    "Dans cet exemple, certaines parties sont à compléter en se référant à la documentation officielle : https://scikit-learn.org/0.21/modules/linear_model.html <br>\n",
    "Dans cet exemple, l'objectif est de prédire la valeur moyenne des maisons dans les districts californiens en utilisant un modèle de régression linéaire puis polynomial.<br>\n",
    "Pour atteindre cet objectif, nous suivrons un processus standard qui se décline en 8 grandes étapes :<br>\n",
    "- Importation et préparation des données avec Pandas\n",
    "- Création d'un jeu de donnée d'entrainement et de test\n",
    "- Création d'un pipeline de transformation applicable aux données d'entrainement et de test\n",
    "- Instanciation et paramètrage d'un modèle de prédiction\n",
    "- Entrainement du modèle à partir du jeu d'entrainement\n",
    "- Validation du modèle à partir du jeu d'entrainement\n",
    "- Performance du modèle mesurée sur jeu de test\n",
    "- Prediction sur de nouvelle données\n",
    "\n",
    "Les deux dernières étapes ne sont envisagées que lorsque le modèle a été validé. Une mauvaise performance sur le jeu de test pour nous conduire à changer les valeurs d'hyperparamètres ou a choisir un autre modèle plus ou moins complexe. Ces ajustements trahissent une forme d'apprentissage sur les données de test que nous ne sommes pas censés connaître."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation et préparation des données avec Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_dir=\"Dataset/\" # chemin relatif vers le fichier de données. A adapter selon l'emplacement choisi pour le fichier de données.\n",
    "data=pd.read_csv(data_dir+\"California_Housing - Copie.csv\",delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nettoyage des données\n",
    "data_cleaned=data.loc[data.population<=5*data.population.std()] # suppression des données aberrantes\n",
    "data_cleaned=data_cleaned.drop(\"total_pools\",axis=1) # suppression de la colonne \"total_pools\" constituée à 50% de valeurs nulles\n",
    "data_cleaned=data_cleaned.drop([\"longitude\",\"latitude\"],axis=1) # suppression des colonnes longitude et latitude\n",
    "data_cleaned=data_cleaned.dropna(axis=0) # supression des lignes contenant au moins une valeur nulle\n",
    "data_cleaned=data_cleaned.astype({'total_rooms': 'float64','ocean_proximity':'category'}) # conversion de type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>845.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>1.5603</td>\n",
       "      <td>78100.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>18.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>2.5568</td>\n",
       "      <td>77100.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2254.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>1.7000</td>\n",
       "      <td>92300.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>741.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>1.8672</td>\n",
       "      <td>84700.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2785.0</td>\n",
       "      <td>616.0</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>530.0</td>\n",
       "      <td>2.3886</td>\n",
       "      <td>89400.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18334 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       housing_median_age  total_rooms  total_bedrooms  population  \\\n",
       "0                    41.0        880.0           129.0       322.0   \n",
       "1                    21.0       7099.0          1106.0      2401.0   \n",
       "2                    52.0       1467.0           190.0       496.0   \n",
       "3                    52.0       1274.0           235.0       558.0   \n",
       "4                    52.0       1627.0           280.0       565.0   \n",
       "...                   ...          ...             ...         ...   \n",
       "20635                25.0       1665.0           374.0       845.0   \n",
       "20636                18.0        697.0           150.0       356.0   \n",
       "20637                17.0       2254.0           485.0      1007.0   \n",
       "20638                18.0       1860.0           409.0       741.0   \n",
       "20639                16.0       2785.0           616.0      1387.0   \n",
       "\n",
       "       households  median_income  median_house_value ocean_proximity  \n",
       "0           126.0         8.3252            452600.0        NEAR BAY  \n",
       "1          1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2           177.0         7.2574            352100.0        NEAR BAY  \n",
       "3           219.0         5.6431            341300.0        NEAR BAY  \n",
       "4           259.0         3.8462            342200.0        NEAR BAY  \n",
       "...           ...            ...                 ...             ...  \n",
       "20635       330.0         1.5603             78100.0          INLAND  \n",
       "20636       114.0         2.5568             77100.0          INLAND  \n",
       "20637       433.0         1.7000             92300.0          INLAND  \n",
       "20638       349.0         1.8672             84700.0          INLAND  \n",
       "20639       530.0         2.3886             89400.0          INLAND  \n",
       "\n",
       "[18334 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création d'un jeu de donnée d'entrainement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisez la fonction train_test_split pour créer un jeu de donnée d'entrainement et de test à partir du dataframe data_cleaned\n",
    "# Faites cette répartition en mettant de côté 20% des données pour la phase de test\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Complétez la ligne de code ci-dessous\n",
    "Train_set, Test_set= train_test_split(data_cleaned,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Il faut maintenant séparer les features des labels\n",
    "# Utilisez les liste features et label pour faire cette séparation\n",
    "features=[\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\",\"ocean_proximity\"]\n",
    "label=[\"median_house_value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-20-dd9d47fa00ca>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-20-dd9d47fa00ca>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    Train_set_features=\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Complétez le code ci-dessous\n",
    "Train_set_features=\n",
    "Test_set_features=\n",
    "Train_set_label=\n",
    "Test_set_label="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création d'un pipeline de transformation applicable aux données d'entrainement et de test\n",
    "Avant de prodécder à l'apprentissage, il est souvent nécessaire de transformer certaines features pour les rendre compatibles avec les logiques propres à chaque algorithme et le type de tâche à réaliser (régression ou classification).<br>\n",
    "- Quel que soit le modèle d'apprentissage utilisé et la tâche à réaliser, il est nécessaire de fournir aux algorithmes des données d'entrée numériques. Dans notre cas, la variable \"ocean_proximity\" doit être transformée en valeurs numérique via le transformateur OrdinalEncoder (documentation : https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html) <br>\n",
    "- La transformation OrdinalEncoder appliquée à  \"ocean_proximity\" génère une nouvelle veriable  categorielle numérique. Dans le cas d'une tâche de régression, une nouvelle transformation de type OneHotEncoder est nécessaire pour ne pas que le choix des valeurs associées aux variables catégorielles influencent la recherche des paramètres du modèle (documentation : https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)<br>\n",
    "- Une dernière transformation consiste à normaliser les varaibles numériques continues pour évacuer l'effet que pourraient avoir des echelles ou des ordres de grandeurs hétérogènes. Cette transformation se fait via StandardScaler (documentation : https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)<br>\n",
    "\n",
    "Toutes ces transformations (OrdinalEncoder,OneHotEncoder et StandardScaler) peuvent être combinées dans un pipeline de type ColumnTransformer (documentation: https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html) qui une fois appliqué aux données réalise les transformation dans l'ordre d'apparatition. Un paramètre permet de préciser à chaque fois quelles sont les colonnes qui doivent subit la transformation.\n",
    "\n",
    "**Remarque:** La transformation OneHotEncoder peut encoder des variables non numériques. Il n'est donc pas nécessaire de faire précéder cette transformation par OrdinalEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importation des classes utiles à la transformation et à la création d'un pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OrdinalEncoder appliqués à la colonne ocean_proximity\n",
    "Ord_Enc=OrdinalEncoder()\n",
    "Ord_Enc.fit(Train_set_features[[\"ocean_proximity\"]])\n",
    "ocean_proximity_Ord_Enc= Ord_Enc.transform(Train_set_features[[\"ocean_proximity\"]])\n",
    "\n",
    "# OneHotEncoder appliqués à la colonne ocean_proximity_Ord_Enc\n",
    "Oh_Enc=OneHotEncoder()\n",
    "Oh_Enc.fit(ocean_proximity_Ord_Enc)\n",
    "ocean_proximity_Oh_Enc=Oh_Enc.transform(ocean_proximity_Ord_Enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichez le contenu de ocean_proximity_Ord_Enc\n",
    "# Quelle interprétation faites-vous des valeurs affichées ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichez le contenu de ocean_proximity_Oh_Enc\n",
    "# Quelle interprétation faites-vous des valeurs affichées ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour appliquer des tranformations sur des groupes de colonnes on peut construire un pipeline de transformations avec un objet ColumnTransformer\n",
    "# Nous commençons par distinguer les variables selon leur type (categorielles ou continues)\n",
    "cat_attribs=[\"ocean_proximity\"]\n",
    "num_attribs=[\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ColumnTransformer prend comme attribut un liste de tuple chacun correspondant à une transformation particulière\n",
    "# L'ordre des transformations est importan\n",
    "# Un tuple représentant une transformation prend la for (\"nom_transformation\",transformateur(),liste_colonne)\n",
    "pipeline=ColumnTransformer([\n",
    "    (\"Hot_encoder\", OneHotEncoder(),cat_attribs),\n",
    "    (\"Scaler\", StandardScaler(),num_attribs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour appliquer le pipeline, il suffit d'invoquer la méthode fit_transform\n",
    "Train_set_features_transformed=pipeline.fit_transform(Train_set_features)  \n",
    "Test_set_features_transformed=pipeline.fit_transform(Test_set_features) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instanciation et paramètrage d'un modèle de prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instanciez un modèle de regression linéaire  simple Lin_reg\n",
    "Lin_reg="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Quelles sont la classes qui permettent de créer des modèles linéaires résularisés ?<br>\n",
    "**Remarque:** Le modèle peut être inégré en dernière étape du pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement du modèle à partir du jeu d'entrainement\n",
    "L'ntrainement du modèle peut se faire simplement via la méthode fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainez le modèle Lin_reg en utilisant le jeu d'entrainement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichez les paramètres (coefficients) du modèle appris\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichez la performance RMSE du modèle mesurée sur le jeu d'entrainement en utilisant la métrique mean_squared_error et la méthode predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions :** <br>\n",
    "- Peut-on savoir si les hyperparamètres sont bons ou pas ?\n",
    "- Peut-on dire que l'hypothèse linéaire est suffisante ?\n",
    "- Peut-on savoir si le modèle sur-apprend ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation du modèle à partir du jeu d'entrainement\n",
    "Pour mesurer la qualité d'un prédicteur et la capcité de généralisation d'un modèle, il est recommandé d'utiliser une partie du jeu d'entrainement pour calculer les paramètres du modèle et une autre partie pour en mesurer la performance.\n",
    "En cas de sur ou sous apprentissage, on peut ainsi recalibrer les hyper-paramètres du modèle sans avoir à utiliser le jeu de test.\n",
    "Pour maximiser l'utilisation des données d'apprentissage pour le calcul des paramètres, une bonne pratique consiste à réaliser une cross-validation par la méthode des K-folds.<br>\n",
    "Consultez la documentation pour comprendre le principe de cette méthode : https://scikit-learn.org/stable/modules/cross_validation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(Lin_reg,Train_set_features_transformed,Train_set_label, cv=3,scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichez le contenu de scores. Que représentent les valeurs qui s'affichent ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Représentation sur un graphe \n",
    "from sklearn.model_selection import learning_curve\n",
    "train_sizes, train_scores, valid_scores = learning_curve(Lin_reg, Train_set_features_transformed, Train_set_label,train_sizes=list(range(100,9700,100)), cv=3,scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Analysez rapidement le contenu de train_sizes, train_scores et valid_scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def Train_validation_curves(train_sizes,train_scores,valid_scores):\n",
    "    t = train_sizes\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    color='tab:red'\n",
    "    ax1.set_xlabel('Training Sample Size')\n",
    "    ax1.set_ylabel('RMSE Train',color=color)\n",
    "    ax1.plot(t, np.mean(np.sqrt(-train_scores),axis=1), color=color,label='Train')\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    color='tab:blue'\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel('RMSE Validation',color=color)\n",
    "    ax2.plot(t, np.mean(np.sqrt(-valid_scores),axis=1),color=color ,label='Validation')\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisez la fonction Train_validation_curves pour afficher les courbes d'apprentissage et de validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Que représentent les points qui ont permis de tracer les courbes bleue et rouge ? (analysez le code de la fonction Train_validation_curves)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance du modèle mesurée sur jeu de test\n",
    "**Questions:**\n",
    "- Si nous considérons que le modèle linéaire est satisfaisant, quelle est la méthode à utiliser pour en mesurer la performance sur le jeu de test ?\n",
    "- Compte tenu des résultats de validation, le modèle linéaire vous semble-t-il satisfaisant ?\n",
    "- Quel phénomène observez vous en analysant les courbes d'apprentissage et de validation ?\n",
    "- Est-il raisonnable de tester ce modèle ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prédictions sur de nouvelles données\n",
    "**Questions:**\n",
    "- Si nous considérons que le modèle linéaire est satisfaisant, quelle est la méthode à utiliser pour faire des prédictions sur de nouvelles données ?\n",
    "- Quelles sont les étapes de préparation à prévoir si ces nouvelles données se présentent sous la même forme que les données d'entrainement et de test ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Régression polynomiale\n",
    "Un modèle polynomial n'est rien d'autres qu'un modèle linéaire entrainé sur les données d'origines auquelles on ajoutes de nouvelles variables calaculées à partir des variables initiales.\n",
    "Nous allons créer un nouveau pipeline qui introduit l'ajout de ces nouvelles variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créez un nouveau pipeline qui intégre une étape d'enrichissement des features\n",
    "# avec de nouvelles varaibles \"polynoamiales\"\n",
    "# utilisez le transformateur PolynomialFeatures (documentation : https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "pipeline=ColumnTransformer([\n",
    "    (\"Hot_encoder\", OneHotEncoder(),cat_attribs),\n",
    "    (\"Scaler\", StandardScaler(),num_attribs),\n",
    "    # complétez le code ici\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer le pipeline à Train_set_features et Test_set_features\n",
    "Train_set_features_transformed=\n",
    "Test_set_features_transformed="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparez les dimensions de Train_set_features_transformed et de Train_set_features\n",
    "# Que remarquez-vous ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainez votre modèle en utilisant une regression linéaire régularisée (lasso) avec descente de gradient stochastique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  8.517923820363152e+22\n"
     ]
    }
   ],
   "source": [
    "# Affichez la Performance (RMSE) du modèle sur données d'entrainement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichez les coefficients du modèle entrainé\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
